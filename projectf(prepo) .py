# -*- coding: utf-8 -*-
"""Projectf(prepo)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dGJuUdkj-_jRBpZ0pbb6gytUffEHPJx6
"""

from google.colab import drive
drive.mount('/content/drive')

import json
tweets = []
for line in open('data.json', 'r'):
    #print(line)
    tweets.append(line)

l=[]
for i in range(0,len(tweets),2):
    l.append(json.loads(tweets[i]))

#create list for text column:
a  = []
for i in range(0,len(l)) :
     a.append(l[i]['text'])  
    
#all the tweets in short form are stored in a list called a

b1 = []
b2 = []
for i in range(0,len(l)) :
    if len(l[i]['text'])==140:
        if 'retweeted_status' in l[i].keys() and 'extended_tweet' in l[i]['retweeted_status'].keys() and 'full_text' in l[i]['retweeted_status']['extended_tweet'].keys() :
            b1.append((l[i]['retweeted_status']['extended_tweet']['full_text']))
    else :
        b2.append(l[i]['text'])

#final list which contains the tweets
f = []
f = b1 + b2

len(f)

# Module 1 (Preprocessing)
# Import the necesary libraries
import re, string, unicodedata
import nltk
from nltk import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import contractions
from langdetect import detect
import pandas as pd

# 1) Remove URL from the tweet set
def remove_URL(sample):
    return re.sub(r"http\S+", " ", sample)

rurl = []
for i in range(0,len(f)) :
    rurl.append(remove_URL(f[i]))

# rurl contains the the tweets without a (i) URL

# 2) Remove the user names mentioned in the tweet
def remove_name(sample) :
    return re.sub(r"RT[^\S]@\S+", " ",sample)

rname = []
for i in range(0,len(rurl)) :
    rname.append(remove_name(rurl[i]))
    
 # rname contains tweets without a (i) URL (ii) Retweeted user name.

# 3) Conversion of uppercase words to lowercase form
def lowercase(sample):
    for word in sample:
        return sample.lower()

lcase = []
for i in range(0,len(f)) :
    lcase.append(lowercase(rname[i]))
    
# lcase contains tweets without a (i) URL (ii) Retweted user name  (iii) Uppercase words

# Remove the null values from the list created due to removal of empty links
lcase  = list(filter(None, lcase))

# 4) Replace contractions
def r_contract(sample) :
    return contractions.fix(sample)

rcont = []
for i in range(0,len(lcase)) :
    rcont.append(r_contract(lcase[i]))

# Before this step null values from the list were removed
# rcont contains the tweets without a (i) URL (ii) Retweeted user name (iii) Uppercase words (iv) Contractions

# 5) Remove the user names mentioned in the tweets
def remove_name2(sample) :
    return re.sub(r"@\S+", " ",sample)

r5 = []
for i in range(0,len(rcont)) :
    r5.append(remove_name2(rcont[i]))
    
# r5 contains the tweets without a (i) URL (ii)Retweeted user name (iii) Uppercase words (iv) Contractions (v) User names

# 6) Remove the \n character
def remove_nl(sample) :
    return re.sub(r"\n", " ",sample)

r4 = []
for i in range(0,len(r5)) :
    r4.append(remove_nl(r5[i]))
# r4 contains the tweets without a (i) URL (ii)Retweeted user name (iii) Uppercase words (iv) Contractions (v) User names (vi) \n character

#7) Remove # from the hashtags mentioned in the tweet
def remove_hash(sample) :
    return re.sub(r"#", " ",sample)

r3 = []
for i in range(0,len(r4)) :
    r3.append(remove_hash(r4[i]))
# r3 contains the tweets without a (i) URL (ii)Retweeted user name (iii) Uppercase words (iv) Contractions (v) User names

# 8) Remove the non-ascii characters eg, \u206 and emoticons etc.
def remove_nascii(sample) :
    return unicodedata.normalize('NFKD', sample).encode('ascii', 'ignore').decode('utf-8', 'ignore')

r2 = []
for i in range(0,len(r3)) :
    r2.append(remove_nascii(r3[i]))
# r2 contains the tweets without a (i) URL (ii) Retweeted user name (iii) Uppercase words (iv) Contractions (v) User names (vi) \n

# 9) Remove &amp sign from the tweets
def remove_amp(sample) :
    return re.sub(r"&amp", " ",sample)

r1 = []
for i in range(0,len(r2)) :
    r1.append(remove_amp(r2[i]))
    
# r1 contains the tweets without a (i) URL (ii) Retweeted user name (iii) Uppercase words (iv) Contractions (v) User names (vi) \n character (vii) Hash symbol (viii) Non-ascii characters (ix) &amp

# Remove comma
def remove_comma(sample) :
    return re.sub(r",", " ",sample)

rc = []
for i in range(0,len(r1)) :
    rc.append(remove_comma(r1[i]))

# Remove colon :
def remove_colon(sample) :
    return re.sub(r":", " ",sample)

rco = []
for i in range(0,len(rc)) :
    rco.append(remove_colon(rc[i]))

# Remove semi-colon
def remove_scolon(sample):
    return re.sub(r";", " ",sample)

rsco = []
for i in range(0,len(rco)) :
    rsco.append(remove_scolon(rco[i]))

# Remove exclamation mark
def remove_ex(sample) :
    return re.sub(r"!", " ",sample)

rex = []
for i in range(0,len(rsco)):
    rex.append(remove_ex(rsco[i]))

# Remove quotes
def remove_q(sample):
    return re.sub(r"'", " ",sample)

rq = []
for i in range(0,len(rex)):
    rq.append(remove_q(rex[i]))

# Remove double quotes
def remove_dq(sample):
    return re.sub(r'"', ' ',sample)

dq = []
for i in range(0,len(rq)):
    dq.append(remove_dq(rq[i]))

# Remove full stop
def remove_fs(sample):
    return re.sub(r"\.", " ",sample)

fs = []
for i in range(0,len(dq)):
    fs.append(remove_fs(dq[i]))

# Remove question mark
def remove_qm(sample):
    return re.sub(r"\?", " ",sample)

qm = []
for i in range(0,len(fs)):
    qm.append(remove_qm(fs[i]))

# Remove asterisk
def remove_ast(sample):
    return re.sub(r"\*", " ",sample)

ra = []
for i in range(0,len(qm)) :
    ra.append(remove_ast(qm[i]))

# Remove numeric characters
def remove_num(sample):
    return re.sub(r'\d+', ' ',sample)

rnum = []
for i in range(0,len(ra)):
    rnum.append(remove_num(ra[i]))

# Remove characters
def remove_b1(sample):
    return re.sub(r'\(', ' ',sample)

def remove_b2(sample):
    return re.sub(r'\)', ' ',sample)

def remove_hy(sample):
    return re.sub(r'\-', ' ',sample)
def remove_bl(sample):
    return re.sub(r'\/', ' ',sample)
def atrate(sample) :
    return re.sub(r'\@', ' ',sample)
def dollar(sample) :
    return re.sub(r'\$', ' ',sample)
def percent(sample) :
    return re.sub(r'\%', ' ',sample)
def pipe(sample) :
    return re.sub(r'\|', ' ',sample)
def equal(sample):
    return re.sub(r'\=', ' ',sample)
def under(sample) :
    return re.sub(r'\_', ' ',sample)
def caret(sample) :
    return re.sub(r'\^','',sample)
def spec(sample) :
    return re.sub(r'[^\w\s]','', sample)
def ws(sample):
    return re.sub('\s+',' ',sample)

r99 = []
for i in range(0,len(rnum)):
    r99.append(ws(spec(remove_b1(remove_b2(remove_hy(remove_bl(atrate(dollar(percent(pipe(equal(under(caret(rnum[i]))))))))))))))

r99  = list(filter(None, r99))

# 10) Remove non-english tweets from the corpus
r100 = []

for i in range(0,len(r99)) :
    r99[i]=r99[i].strip()
for i in range(len(r99)):
    if r99[i] != '' and detect(r99[i]) == 'en':
        r100.append(r99[i])

df = pd.DataFrame(r100, columns = ['Tweet'], index=None)
pd.set_option('display.max_colwidth', 100000000000)

import pickle
with open('label.pkl', 'wb') as f:
     pickle.dump(df, f)